{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: konlpy in /opt/conda/lib/python3.10/site-packages (0.6.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from konlpy) (1.5.0)\n",
      "Requirement already satisfied: lxml>=4.1.0 in /opt/conda/lib/python3.10/site-packages (from konlpy) (5.3.0)\n",
      "Requirement already satisfied: numpy>=1.6 in /opt/conda/lib/python3.10/site-packages (from konlpy) (1.26.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from JPype1>=0.7.0->konlpy) (23.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: seaborn in /opt/conda/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /opt/conda/lib/python3.10/site-packages (from seaborn) (1.26.0)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/conda/lib/python3.10/site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /opt/conda/lib/python3.10/site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.1)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting kiwipiepy\n",
      "  Obtaining dependency information for kiwipiepy from https://files.pythonhosted.org/packages/3e/42/7b090e50bc1b0bd0ac89bbedb280f6703e10a6319e5c5973d72805e575e4/kiwipiepy-0.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading kiwipiepy-0.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting kiwipiepy-model<0.21,>=0.20 (from kiwipiepy)\n",
      "  Downloading kiwipiepy_model-0.20.0.tar.gz (34.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.7/34.7 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from kiwipiepy) (4.66.6)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from kiwipiepy) (1.26.0)\n",
      "Downloading kiwipiepy-0.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: kiwipiepy-model\n",
      "  Building wheel for kiwipiepy-model (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kiwipiepy-model: filename=kiwipiepy_model-0.20.0-py3-none-any.whl size=34818023 sha256=7b6abcc067b4723c40c78f36d886f9860ca4dc61bf8e45b636ed710ab9489acf\n",
      "  Stored in directory: /data/ephemeral/home/.cache/pip/wheels/b6/b1/66/2be9840f8ef3627d63d93503d81a5e3b41e9498dcb63b00b13\n",
      "Successfully built kiwipiepy-model\n",
      "Installing collected packages: kiwipiepy-model, kiwipiepy\n",
      "Successfully installed kiwipiepy-0.20.1 kiwipiepy-model-0.20.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 설치\n",
    "!pip install konlpy\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install kiwipiepy\n",
    "!pip install transformers sentencepiece\n",
    "!pip install datasets\n",
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.1)\n",
      "Requirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.3)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.1.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.6)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2023.9.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (18.0.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.10.10)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.17.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U transformers evaluate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     토큰  빈도수\n",
      "0     …  783\n",
      "1     ·  333\n",
      "2     에  303\n",
      "3     ᆫ  227\n",
      "4     하  227\n",
      "5     어  209\n",
      "6     2  208\n",
      "7    종합  173\n",
      "8     로  134\n",
      "9     는  121\n",
      "10    1  118\n",
      "11    의  118\n",
      "12    이  112\n",
      "13    은  102\n",
      "14    美  100\n",
      "15    3   99\n",
      "16    4   99\n",
      "17    만   94\n",
      "18    서   92\n",
      "19    5   87\n",
      "20    도   86\n",
      "21    일   80\n",
      "22    원   80\n",
      "23    년   75\n",
      "24    %   75\n",
      "25    대   72\n",
      "26    다   68\n",
      "27  대통령   67\n",
      "28    8   62\n",
      "29   으로   60\n"
     ]
    }
   ],
   "source": [
    "from kiwipiepy import Kiwi\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "# 데이터셋 로드 (예시 데이터 사용)\n",
    "data = pd.read_csv('/data/ephemeral/data/filtered_texts_test.csv')  # 실제 파일 경로로 변경하세요.\n",
    "\n",
    "# 형태소 분석기 초기화\n",
    "kiwi = Kiwi()\n",
    "\n",
    "# 모든 토큰을 저장할 리스트\n",
    "all_tokens = []\n",
    "\n",
    "# 각 텍스트에 대한 토큰화\n",
    "for text in data['text']:\n",
    "    tokens = [word.form for word in kiwi.tokenize(text)]\n",
    "    all_tokens.extend(tokens)\n",
    "\n",
    "# 토큰 빈도수 계산\n",
    "token_counts = Counter(all_tokens)\n",
    "\n",
    "# 상위 30개 빈도수 추출\n",
    "most_common_tokens = token_counts.most_common(30)\n",
    "\n",
    "# 데이터프레임으로 변환\n",
    "token_freq_df = pd.DataFrame(most_common_tokens, columns=['토큰', '빈도수'])\n",
    "print(token_freq_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 48712 (\\N{HANGUL SYLLABLE BIN}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 46020 (\\N{HANGUL SYLLABLE DO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 49688 (\\N{HANGUL SYLLABLE SU}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 53664 (\\N{HANGUL SYLLABLE TO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 53360 (\\N{HANGUL SYLLABLE KEUN}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 49345 (\\N{HANGUL SYLLABLE SANG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 50948 (\\N{HANGUL SYLLABLE WI}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 44060 (\\N{HANGUL SYLLABLE GAE}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 50640 (\\N{HANGUL SYLLABLE E}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 4523 (\\N{HANGUL JONGSEONG NIEUN}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 54616 (\\N{HANGUL SYLLABLE HA}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 50612 (\\N{HANGUL SYLLABLE EO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 51333 (\\N{HANGUL SYLLABLE JONG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 54633 (\\N{HANGUL SYLLABLE HAB}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 47196 (\\N{HANGUL SYLLABLE RO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 45716 (\\N{HANGUL SYLLABLE NEUN}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 51032 (\\N{HANGUL SYLLABLE YI}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 51060 (\\N{HANGUL SYLLABLE I}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 51008 (\\N{HANGUL SYLLABLE EUN}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 32654 (\\N{CJK UNIFIED IDEOGRAPH-7F8E}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 47564 (\\N{HANGUL SYLLABLE MAN}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 49436 (\\N{HANGUL SYLLABLE SEO}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 51068 (\\N{HANGUL SYLLABLE IL}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 50896 (\\N{HANGUL SYLLABLE WEON}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 45380 (\\N{HANGUL SYLLABLE NYEON}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 45824 (\\N{HANGUL SYLLABLE DAE}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 45796 (\\N{HANGUL SYLLABLE DA}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 53685 (\\N{HANGUL SYLLABLE TONG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 47161 (\\N{HANGUL SYLLABLE RYEONG}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "/opt/conda/lib/python3.10/site-packages/IPython/core/pylabtools.py:152: UserWarning: Glyph 51004 (\\N{HANGUL SYLLABLE EU}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import platform\n",
    "from matplotlib import font_manager, rc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 한글 폰트 설정\n",
    "if platform.system() == 'Darwin':  # Mac\n",
    "    rc('font', family='AppleGothic')\n",
    "elif platform.system() == 'Windows':  # Windows\n",
    "    font_name = font_manager.FontProperties(fname='c:/Windows/Fonts/malgun.ttf').get_name()\n",
    "    rc('font', family=font_name)\n",
    "else:  # Linux (예: Ubuntu)\n",
    "    rc('font', family='NanumGothic')\n",
    "\n",
    "# 그래프 시각화\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='토큰', y='빈도수', data=token_freq_df)\n",
    "plt.title('토큰 빈도수 상위 30개')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 'UNK' 토큰 개수: 57\n",
      "UNK 토큰 포함 텍스트 예시 (최대 5개):\n",
      "텍스트 인덱스: 15, UNK 토큰 개수: 1\n",
      "토큰 리스트: ['G', '##D', '이스라엘', '강팀', '감독', '##으로', '축구', '##연맹', 'W', '[UNK]', '참가']\n",
      "------------\n",
      "텍스트 인덱스: 79, UNK 토큰 개수: 1\n",
      "토큰 리스트: ['2', '##개', '##월', '전보', '##다', '74', '%', '감소', '##해', '…', '전년', '##보도', '3', '.', '1', '%', '[UNK]']\n",
      "------------\n",
      "텍스트 인덱스: 104, UNK 토큰 개수: 1\n",
      "토큰 리스트: ['KB', '##증권', '오리온', '중간', '성장', '##둔', '##점', '…', '[UNK]']\n",
      "------------\n",
      "텍스트 인덱스: 105, UNK 토큰 개수: 1\n",
      "토큰 리스트: ['유', '##튜', '##버', '공공', '##기', '##관', '손', '##에', '독재', '…', '[UNK]', '집', '명', '##패', '##에', '넘', '##는', '##다']\n",
      "------------\n",
      "텍스트 인덱스: 130, UNK 토큰 개수: 1\n",
      "토큰 리스트: ['[UNK]', '공사', '파키스탄', '내', '4', '##개', '공사', '중단', '…', '기타', '공사', '고조', '##종합']\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# 데이터셋 로드\n",
    "data = pd.read_csv('/data/ephemeral/data/filtered_texts_test.csv')  \n",
    "\n",
    "# 토크나이저 로드\n",
    "tokenizer = BertTokenizer.from_pretrained('klue/bert-base')\n",
    "\n",
    "# 모든 텍스트를 토큰화하고 'unk' 토큰의 빈도수와 위치 파악\n",
    "unk_counts = []\n",
    "unk_tokens_in_texts = {}\n",
    "\n",
    "for idx, text in enumerate(data['text']):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    unk_count = tokens.count(tokenizer.unk_token)  # unk 토큰 개수 확인\n",
    "    if unk_count > 0:\n",
    "        unk_counts.append(unk_count)\n",
    "        unk_tokens_in_texts[idx] = tokens  # 'unk' 토큰이 포함된 전체 토큰 리스트 저장\n",
    "\n",
    "# unk 토큰 빈도 출력\n",
    "total_unk_count = sum(unk_counts)\n",
    "print(f\"총 'UNK' 토큰 개수: {total_unk_count}\")\n",
    "\n",
    "# unk 토큰이 포함된 텍스트의 예시를 출력\n",
    "print(\"UNK 토큰 포함 텍스트 예시 (최대 5개):\")\n",
    "for i, (idx, tokens) in enumerate(unk_tokens_in_texts.items()):\n",
    "    if i >= 5:  # 최대 5개 예시만 출력\n",
    "        break\n",
    "    print(f\"텍스트 인덱스: {idx}, UNK 토큰 개수: {tokens.count(tokenizer.unk_token)}\")\n",
    "    print(f\"토큰 리스트: {tokens}\")\n",
    "    print(\"------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 데이터셋 로드\n",
    "data = pd.read_csv('/data/ephemeral/data/new_labeled_dataset_ens.csv')\n",
    "\n",
    "# target 클래스 분포 확인\n",
    "target_counts = data['target'].value_counts()\n",
    "\n",
    "# 클래스 분포 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=target_counts.index, y=target_counts.values)\n",
    "plt.title(\"Target Class Distribution\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kobert_transformers\n",
      "  Obtaining dependency information for kobert_transformers from https://files.pythonhosted.org/packages/77/af/2a85216d5a4faf2d29fa8325cfdda9f29f8b4d3ad56040162dfb8fca6992/kobert_transformers-0.6.0-py3-none-any.whl.metadata\n",
      "  Downloading kobert_transformers-0.6.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: torch>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from kobert_transformers) (2.1.0)\n",
      "Requirement already satisfied: transformers<5,>=3 in /opt/conda/lib/python3.10/site-packages (from kobert_transformers) (4.46.1)\n",
      "Requirement already satisfied: sentencepiece>=0.1.91 in /opt/conda/lib/python3.10/site-packages (from kobert_transformers) (0.2.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.1.0->kobert_transformers) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.1.0->kobert_transformers) (4.7.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.1.0->kobert_transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.1.0->kobert_transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.1.0->kobert_transformers) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.1.0->kobert_transformers) (2023.9.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers<5,>=3->kobert_transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5,>=3->kobert_transformers) (1.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers<5,>=3->kobert_transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5,>=3->kobert_transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5,>=3->kobert_transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers<5,>=3->kobert_transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5,>=3->kobert_transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers<5,>=3->kobert_transformers) (0.20.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers<5,>=3->kobert_transformers) (4.66.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.1.0->kobert_transformers) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers<5,>=3->kobert_transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers<5,>=3->kobert_transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers<5,>=3->kobert_transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers<5,>=3->kobert_transformers) (2024.8.30)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.1.0->kobert_transformers) (1.3.0)\n",
      "Downloading kobert_transformers-0.6.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: kobert_transformers\n",
      "Successfully installed kobert_transformers-0.6.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install kobert_transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1065' max='1065' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1065/1065 02:53, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.956800</td>\n",
       "      <td>1.951300</td>\n",
       "      <td>0.183422</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.111424</td>\n",
       "      <td>0.183422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.924700</td>\n",
       "      <td>1.917092</td>\n",
       "      <td>0.264550</td>\n",
       "      <td>0.198446</td>\n",
       "      <td>0.222793</td>\n",
       "      <td>0.264550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.874200</td>\n",
       "      <td>1.828597</td>\n",
       "      <td>0.430335</td>\n",
       "      <td>0.382402</td>\n",
       "      <td>0.446557</td>\n",
       "      <td>0.430335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.601700</td>\n",
       "      <td>1.538013</td>\n",
       "      <td>0.573192</td>\n",
       "      <td>0.546517</td>\n",
       "      <td>0.583095</td>\n",
       "      <td>0.573192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.398100</td>\n",
       "      <td>1.314073</td>\n",
       "      <td>0.643739</td>\n",
       "      <td>0.631190</td>\n",
       "      <td>0.660799</td>\n",
       "      <td>0.643739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.238300</td>\n",
       "      <td>1.175100</td>\n",
       "      <td>0.649030</td>\n",
       "      <td>0.639597</td>\n",
       "      <td>0.655692</td>\n",
       "      <td>0.649030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.099300</td>\n",
       "      <td>1.086320</td>\n",
       "      <td>0.661376</td>\n",
       "      <td>0.655901</td>\n",
       "      <td>0.663369</td>\n",
       "      <td>0.661376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.907000</td>\n",
       "      <td>1.047247</td>\n",
       "      <td>0.687831</td>\n",
       "      <td>0.683878</td>\n",
       "      <td>0.688705</td>\n",
       "      <td>0.687831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.695200</td>\n",
       "      <td>1.008197</td>\n",
       "      <td>0.701940</td>\n",
       "      <td>0.700575</td>\n",
       "      <td>0.703437</td>\n",
       "      <td>0.701940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.647500</td>\n",
       "      <td>1.008352</td>\n",
       "      <td>0.708995</td>\n",
       "      <td>0.709672</td>\n",
       "      <td>0.712398</td>\n",
       "      <td>0.708995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.670500</td>\n",
       "      <td>1.004153</td>\n",
       "      <td>0.708995</td>\n",
       "      <td>0.709467</td>\n",
       "      <td>0.711587</td>\n",
       "      <td>0.708995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.526000</td>\n",
       "      <td>0.996264</td>\n",
       "      <td>0.717813</td>\n",
       "      <td>0.717391</td>\n",
       "      <td>0.719884</td>\n",
       "      <td>0.717813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.427900</td>\n",
       "      <td>1.004567</td>\n",
       "      <td>0.705467</td>\n",
       "      <td>0.706358</td>\n",
       "      <td>0.709597</td>\n",
       "      <td>0.705467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.490500</td>\n",
       "      <td>1.010644</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.702555</td>\n",
       "      <td>0.707617</td>\n",
       "      <td>0.703704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.395000</td>\n",
       "      <td>0.994810</td>\n",
       "      <td>0.719577</td>\n",
       "      <td>0.719346</td>\n",
       "      <td>0.719387</td>\n",
       "      <td>0.719577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, EarlyStoppingCallback, AutoTokenizer, AutoModelForSequenceClassification, ElectraTokenizer,ElectraForSequenceClassification\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from kobert_transformers  import get_tokenizer\n",
    "import re\n",
    "import os\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    precision = precision_score(labels, preds, average=\"weighted\")\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")\n",
    "    return {\"accuracy\": accuracy, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
    "\n",
    "\n",
    "# 데이터셋 로드\n",
    "data = pd.read_csv('/data/ephemeral/data/train_aug_test_cleaned.csv')\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^가-힣a-zA-Z0-9\\s]', '', text)  # 한글, 영어, 숫자, 공백 제외 모두 제거\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # 연속된 공백을 하나의 공백으로 변환\n",
    "    return text\n",
    "\n",
    "\n",
    "# 텍스트 전처리 적용\n",
    "data['text'] = data['text'].apply(clean_text)\n",
    "\n",
    "# 분류할 클래스 수 설정\n",
    "num_labels = len(data['target'].unique())  # 데이터에 맞게 클래스 수 확인\n",
    "\n",
    "# 데이터 분리\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    data['text'], data['target'], test_size=0.2, random_state=42)\n",
    "\n",
    "model_name = 'monologg/kobert'\n",
    "\n",
    "# 토크나이저 및 모델 로드 (동일 모델 사용)\n",
    "# tokenizer = ElectraTokenizer.from_pretrained(model_name)  # ELECTRA 토크나이저 불러오기\n",
    "# model = ElectraForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)  \n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "\n",
    "\n",
    "# 텍스트 토큰화\n",
    "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=128)\n",
    "val_encodings = tokenizer(list(val_texts), truncation=True, padding=True, max_length=128)\n",
    "\n",
    "# 데이터셋 클래스 정의\n",
    "class NewsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels.reset_index(drop=True)\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(int(self.labels[idx]))\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# 데이터셋 생성\n",
    "train_dataset = NewsDataset(train_encodings, train_labels)\n",
    "val_dataset = NewsDataset(val_encodings, val_labels)\n",
    "\n",
    "# 출력 및 체크포인트 저장 디렉토리 설정\n",
    "output_dir = Path('./results')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 트레이너 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=str(output_dir),         \n",
    "    report_to=[],\n",
    "    num_train_epochs=15,                  \n",
    "    per_device_train_batch_size=32,     \n",
    "    per_device_eval_batch_size=32,       \n",
    "    warmup_steps=500,                    \n",
    "    weight_decay=0.01,                   \n",
    "    logging_dir='./logs',               \n",
    "    logging_steps=10,\n",
    "    evaluation_strategy='epoch',         \n",
    "    save_strategy='epoch',               \n",
    "    save_total_limit=2,\n",
    "    learning_rate=1e-5,\n",
    "    load_best_model_at_end=True,          # 최적의 모델 로드\n",
    "    metric_for_best_model=\"f1\",           # f1 기준으로 최적 모델 선택\n",
    "    greater_is_better=True                # 높은 f1 값이 더 좋은 것으로 설정\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStoppingCallback(\n",
    "    early_stopping_patience=3,           # 성능 개선 없을 경우 대기할 에포크 수\n",
    "    early_stopping_threshold=0.001       # 개선으로 간주될 최소 변화량 (optional)\n",
    ")\n",
    "\n",
    "# 트레이너 생성\n",
    "trainer = Trainer(\n",
    "    model=model,                         \n",
    "    args=training_args,                  \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[early_stopping]            \n",
    ")\n",
    "\n",
    "# 모델 학습\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "# 모델 수동 저장\n",
    "best_model_dir = \"./results\"\n",
    "os.makedirs(best_model_dir, exist_ok=True)  # 경로가 없으면 생성\n",
    "best_model_path = f\"{best_model_dir}/{model_name.split('/')[-1]}.bin\"\n",
    "\n",
    "trainer.save_model(output_dir)  # 기본 체크포인트 저장\n",
    "torch.save(model.state_dict(), best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: monologg/koelectra-base-v3-discriminator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1278' max='1278' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1278/1278 03:34, Epoch 18/18]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.948600</td>\n",
       "      <td>1.945452</td>\n",
       "      <td>0.121693</td>\n",
       "      <td>0.055796</td>\n",
       "      <td>0.036196</td>\n",
       "      <td>0.121693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.942300</td>\n",
       "      <td>1.939598</td>\n",
       "      <td>0.146384</td>\n",
       "      <td>0.066048</td>\n",
       "      <td>0.213363</td>\n",
       "      <td>0.146384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.916200</td>\n",
       "      <td>1.919605</td>\n",
       "      <td>0.234568</td>\n",
       "      <td>0.143824</td>\n",
       "      <td>0.213909</td>\n",
       "      <td>0.234568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.880000</td>\n",
       "      <td>1.856974</td>\n",
       "      <td>0.336861</td>\n",
       "      <td>0.249660</td>\n",
       "      <td>0.270318</td>\n",
       "      <td>0.336861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.790400</td>\n",
       "      <td>1.761946</td>\n",
       "      <td>0.356261</td>\n",
       "      <td>0.272626</td>\n",
       "      <td>0.265322</td>\n",
       "      <td>0.356261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.695300</td>\n",
       "      <td>1.652690</td>\n",
       "      <td>0.388007</td>\n",
       "      <td>0.323661</td>\n",
       "      <td>0.471930</td>\n",
       "      <td>0.388007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.521200</td>\n",
       "      <td>1.530994</td>\n",
       "      <td>0.479718</td>\n",
       "      <td>0.428153</td>\n",
       "      <td>0.563173</td>\n",
       "      <td>0.479718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.387900</td>\n",
       "      <td>1.404246</td>\n",
       "      <td>0.562610</td>\n",
       "      <td>0.540337</td>\n",
       "      <td>0.652248</td>\n",
       "      <td>0.562610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.235300</td>\n",
       "      <td>1.295104</td>\n",
       "      <td>0.613757</td>\n",
       "      <td>0.598369</td>\n",
       "      <td>0.645401</td>\n",
       "      <td>0.613757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.130000</td>\n",
       "      <td>1.215699</td>\n",
       "      <td>0.643739</td>\n",
       "      <td>0.639643</td>\n",
       "      <td>0.660615</td>\n",
       "      <td>0.643739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.073200</td>\n",
       "      <td>1.162675</td>\n",
       "      <td>0.659612</td>\n",
       "      <td>0.656882</td>\n",
       "      <td>0.665835</td>\n",
       "      <td>0.659612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.957400</td>\n",
       "      <td>1.116504</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.663635</td>\n",
       "      <td>0.671491</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.790100</td>\n",
       "      <td>1.097247</td>\n",
       "      <td>0.657848</td>\n",
       "      <td>0.656757</td>\n",
       "      <td>0.663448</td>\n",
       "      <td>0.657848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.836100</td>\n",
       "      <td>1.051790</td>\n",
       "      <td>0.693122</td>\n",
       "      <td>0.689275</td>\n",
       "      <td>0.693073</td>\n",
       "      <td>0.693122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.708400</td>\n",
       "      <td>1.036923</td>\n",
       "      <td>0.700176</td>\n",
       "      <td>0.697467</td>\n",
       "      <td>0.700768</td>\n",
       "      <td>0.700176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.718400</td>\n",
       "      <td>1.015444</td>\n",
       "      <td>0.700176</td>\n",
       "      <td>0.697701</td>\n",
       "      <td>0.697812</td>\n",
       "      <td>0.700176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.729000</td>\n",
       "      <td>1.011925</td>\n",
       "      <td>0.696649</td>\n",
       "      <td>0.694698</td>\n",
       "      <td>0.696581</td>\n",
       "      <td>0.696649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.657700</td>\n",
       "      <td>1.014584</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>0.689427</td>\n",
       "      <td>0.689856</td>\n",
       "      <td>0.691358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: klue/bert-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1278' max='1278' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1278/1278 03:29, Epoch 18/18]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.988500</td>\n",
       "      <td>1.960421</td>\n",
       "      <td>0.167549</td>\n",
       "      <td>0.129625</td>\n",
       "      <td>0.194841</td>\n",
       "      <td>0.167549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.836000</td>\n",
       "      <td>1.817506</td>\n",
       "      <td>0.365079</td>\n",
       "      <td>0.358354</td>\n",
       "      <td>0.369000</td>\n",
       "      <td>0.365079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.676100</td>\n",
       "      <td>1.597551</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>0.502440</td>\n",
       "      <td>0.533608</td>\n",
       "      <td>0.507937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.384900</td>\n",
       "      <td>1.304970</td>\n",
       "      <td>0.615520</td>\n",
       "      <td>0.611874</td>\n",
       "      <td>0.614945</td>\n",
       "      <td>0.615520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.184500</td>\n",
       "      <td>1.117156</td>\n",
       "      <td>0.656085</td>\n",
       "      <td>0.653934</td>\n",
       "      <td>0.653488</td>\n",
       "      <td>0.656085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.047700</td>\n",
       "      <td>1.032107</td>\n",
       "      <td>0.671958</td>\n",
       "      <td>0.671251</td>\n",
       "      <td>0.676131</td>\n",
       "      <td>0.671958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.913100</td>\n",
       "      <td>0.986643</td>\n",
       "      <td>0.675485</td>\n",
       "      <td>0.674585</td>\n",
       "      <td>0.675564</td>\n",
       "      <td>0.675485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.725100</td>\n",
       "      <td>1.000519</td>\n",
       "      <td>0.694885</td>\n",
       "      <td>0.692581</td>\n",
       "      <td>0.703813</td>\n",
       "      <td>0.694885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.514200</td>\n",
       "      <td>0.943482</td>\n",
       "      <td>0.700176</td>\n",
       "      <td>0.698246</td>\n",
       "      <td>0.699240</td>\n",
       "      <td>0.700176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.415500</td>\n",
       "      <td>0.941100</td>\n",
       "      <td>0.719577</td>\n",
       "      <td>0.717842</td>\n",
       "      <td>0.729837</td>\n",
       "      <td>0.719577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.371300</td>\n",
       "      <td>0.921493</td>\n",
       "      <td>0.726631</td>\n",
       "      <td>0.726868</td>\n",
       "      <td>0.727903</td>\n",
       "      <td>0.726631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.248100</td>\n",
       "      <td>0.913007</td>\n",
       "      <td>0.730159</td>\n",
       "      <td>0.728796</td>\n",
       "      <td>0.728933</td>\n",
       "      <td>0.730159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.167200</td>\n",
       "      <td>0.969864</td>\n",
       "      <td>0.726631</td>\n",
       "      <td>0.723784</td>\n",
       "      <td>0.729399</td>\n",
       "      <td>0.726631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.163800</td>\n",
       "      <td>0.953489</td>\n",
       "      <td>0.731922</td>\n",
       "      <td>0.730098</td>\n",
       "      <td>0.731234</td>\n",
       "      <td>0.731922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.092200</td>\n",
       "      <td>0.977876</td>\n",
       "      <td>0.738977</td>\n",
       "      <td>0.735940</td>\n",
       "      <td>0.740044</td>\n",
       "      <td>0.738977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.993859</td>\n",
       "      <td>0.738977</td>\n",
       "      <td>0.737324</td>\n",
       "      <td>0.741143</td>\n",
       "      <td>0.738977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.110300</td>\n",
       "      <td>0.997518</td>\n",
       "      <td>0.742504</td>\n",
       "      <td>0.740300</td>\n",
       "      <td>0.741694</td>\n",
       "      <td>0.742504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.106500</td>\n",
       "      <td>1.001505</td>\n",
       "      <td>0.744268</td>\n",
       "      <td>0.742412</td>\n",
       "      <td>0.744527</td>\n",
       "      <td>0.744268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model: beomi/kcbert-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1278' max='1278' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1278/1278 03:09, Epoch 18/18]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.963700</td>\n",
       "      <td>1.949325</td>\n",
       "      <td>0.174603</td>\n",
       "      <td>0.091696</td>\n",
       "      <td>0.118613</td>\n",
       "      <td>0.174603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.794900</td>\n",
       "      <td>1.747592</td>\n",
       "      <td>0.449735</td>\n",
       "      <td>0.413823</td>\n",
       "      <td>0.443968</td>\n",
       "      <td>0.449735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.530000</td>\n",
       "      <td>1.431717</td>\n",
       "      <td>0.530864</td>\n",
       "      <td>0.508961</td>\n",
       "      <td>0.567223</td>\n",
       "      <td>0.530864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.276300</td>\n",
       "      <td>1.212711</td>\n",
       "      <td>0.608466</td>\n",
       "      <td>0.603634</td>\n",
       "      <td>0.617989</td>\n",
       "      <td>0.608466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.179700</td>\n",
       "      <td>1.129067</td>\n",
       "      <td>0.622575</td>\n",
       "      <td>0.619045</td>\n",
       "      <td>0.638670</td>\n",
       "      <td>0.622575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.981700</td>\n",
       "      <td>1.061351</td>\n",
       "      <td>0.640212</td>\n",
       "      <td>0.641053</td>\n",
       "      <td>0.657380</td>\n",
       "      <td>0.640212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.786100</td>\n",
       "      <td>1.017504</td>\n",
       "      <td>0.663139</td>\n",
       "      <td>0.661443</td>\n",
       "      <td>0.673312</td>\n",
       "      <td>0.663139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.562700</td>\n",
       "      <td>0.952695</td>\n",
       "      <td>0.701940</td>\n",
       "      <td>0.701393</td>\n",
       "      <td>0.708287</td>\n",
       "      <td>0.701940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.384800</td>\n",
       "      <td>0.951070</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.703918</td>\n",
       "      <td>0.713044</td>\n",
       "      <td>0.703704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.215600</td>\n",
       "      <td>0.926454</td>\n",
       "      <td>0.733686</td>\n",
       "      <td>0.733127</td>\n",
       "      <td>0.743596</td>\n",
       "      <td>0.733686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.184600</td>\n",
       "      <td>0.913833</td>\n",
       "      <td>0.742504</td>\n",
       "      <td>0.743048</td>\n",
       "      <td>0.744114</td>\n",
       "      <td>0.742504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.113200</td>\n",
       "      <td>1.039853</td>\n",
       "      <td>0.723104</td>\n",
       "      <td>0.724288</td>\n",
       "      <td>0.737039</td>\n",
       "      <td>0.723104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.039200</td>\n",
       "      <td>0.975607</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.741584</td>\n",
       "      <td>0.748074</td>\n",
       "      <td>0.740741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.055200</td>\n",
       "      <td>1.015870</td>\n",
       "      <td>0.744268</td>\n",
       "      <td>0.745858</td>\n",
       "      <td>0.752948</td>\n",
       "      <td>0.744268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>1.050946</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.740639</td>\n",
       "      <td>0.749603</td>\n",
       "      <td>0.740741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.016500</td>\n",
       "      <td>1.066572</td>\n",
       "      <td>0.747795</td>\n",
       "      <td>0.748401</td>\n",
       "      <td>0.755329</td>\n",
       "      <td>0.747795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>1.055962</td>\n",
       "      <td>0.751323</td>\n",
       "      <td>0.751854</td>\n",
       "      <td>0.757847</td>\n",
       "      <td>0.751323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>1.058503</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>0.753500</td>\n",
       "      <td>0.758559</td>\n",
       "      <td>0.753086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Results - Accuracy: 0.7918871252204586, F1: 0.7908781270387317, Precision: 0.7914640201263962, Recall: 0.7918871252204586\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from pathlib import Path\n",
    "import os\n",
    "import re\n",
    "\n",
    "# 모델과 토크나이저 임포트\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, ElectraTokenizer,ElectraForSequenceClassification\n",
    "\n",
    "# 데이터셋 로드 및 전처리 함수 정의\n",
    "data = pd.read_csv('/data/ephemeral/data/train_aug_test_cleaned.csv')\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^가-힣a-zA-Z0-9\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "data['text'] = data['text'].apply(clean_text)\n",
    "\n",
    "# 분류할 클래스 수 설정\n",
    "num_labels = len(data['target'].unique())\n",
    "\n",
    "# 데이터 분할\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    data['text'], data['target'], test_size=0.2, random_state=42)\n",
    "\n",
    "# 모델 이름 목록과 전용 토크나이저 설정\n",
    "model_names = [\n",
    "    'monologg/koelectra-base-v3-discriminator',\n",
    "    'klue/bert-base',\n",
    "    'beomi/kcbert-base',\n",
    "    # 'klue/roberta-large'\n",
    "]\n",
    "\n",
    "# 데이터셋 클래스 정의\n",
    "class NewsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels.reset_index(drop=True)\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(int(self.labels[idx]))\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "# 메트릭 계산 함수 정의\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    precision = precision_score(labels, preds, average=\"weighted\")\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")\n",
    "    return {\"accuracy\": accuracy, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
    "\n",
    "# 결과 저장 경로\n",
    "output_dir = Path('./results')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 앙상블을 위한 예측 저장 리스트\n",
    "ensemble_predictions = []\n",
    "\n",
    "# 모델별 학습 루프\n",
    "for model_name in model_names:\n",
    "    print(f\"Training model: {model_name}\")\n",
    "\n",
    "    # 모델과 전용 토크나이저 로드\n",
    "    if model_name in \"koelectra\":\n",
    "            tokenizer = ElectraTokenizer.from_pretrained(model_name)\n",
    "            model = ElectraForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "    else:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "\n",
    "    # 텍스트 토큰화\n",
    "    train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=128)\n",
    "    val_encodings = tokenizer(list(val_texts), truncation=True, padding=True, max_length=128)\n",
    "\n",
    "    # 데이터셋 생성\n",
    "    train_dataset = NewsDataset(train_encodings, train_labels)\n",
    "    val_dataset = NewsDataset(val_encodings, val_labels)\n",
    "\n",
    "    # 트레이너 설정\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=str(output_dir / model_name.split(\"/\")[-1]),         \n",
    "        report_to=[],\n",
    "        num_train_epochs=18,\n",
    "        per_device_train_batch_size=32,\n",
    "        per_device_eval_batch_size=32,\n",
    "        warmup_steps=500,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=10,\n",
    "        evaluation_strategy='epoch',\n",
    "        save_strategy='epoch',\n",
    "        save_total_limit=2,\n",
    "        learning_rate=1e-5,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        greater_is_better=True\n",
    "    )\n",
    "\n",
    "    early_stopping = EarlyStoppingCallback(\n",
    "        early_stopping_patience=3,\n",
    "        early_stopping_threshold=0.001\n",
    "    )\n",
    "\n",
    "    # 트레이너 생성\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "\n",
    "    # 모델 학습\n",
    "    trainer.train()\n",
    "\n",
    "    # 검증 데이터에 대한 예측 저장 (앙상블용)\n",
    "    predictions = trainer.predict(val_dataset)\n",
    "    ensemble_predictions.append(predictions.predictions)\n",
    "\n",
    "# 앙상블: 모델별 예측을 평균하여 최종 예측 생성\n",
    "final_preds = sum(ensemble_predictions) / len(ensemble_predictions)\n",
    "final_labels = final_preds.argmax(axis=1)\n",
    "\n",
    "# 최종 앙상블 결과 평가\n",
    "accuracy = accuracy_score(val_labels, final_labels)\n",
    "f1 = f1_score(val_labels, final_labels, average=\"weighted\")\n",
    "precision = precision_score(val_labels, final_labels, average=\"weighted\")\n",
    "recall = recall_score(val_labels, final_labels, average=\"weighted\")\n",
    "\n",
    "print(f\"Ensemble Results - Accuracy: {accuracy}, F1: {f1}, Precision: {precision}, Recall: {recall}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at monologg/kobert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 130/130 [00:02<00:00, 50.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference completed and results saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 새 데이터셋 로드\n",
    "new_data = pd.read_csv('/data/ephemeral/jung/merged_train_kobert.csv')\n",
    "\n",
    "# 텍스트 전처리 함수\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^가-힣a-zA-Z0-9\\s]', '', text)  # 한글, 영어, 숫자, 공백 제외 모두 제거\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # 연속된 공백을 하나의 공백으로 변환\n",
    "    return text\n",
    "\n",
    "new_data['text'] = new_data['text'].apply(clean_text)\n",
    "\n",
    "# 모델과 토크나이저 로드\n",
    "model_path = './results'  # 학습된 모델이 저장된 경로\n",
    "model_name = \"monologg/kobert\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name,trust_remote_code=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=7)  # num_labels를 7로 설정\n",
    "\n",
    "# 모델의 가중치 파일 로드\n",
    "model.load_state_dict(torch.load(f\"{model_path}/{model_name.split('/')[-1]}.bin\"))  # 저장된 가중치 파일 경로 수정\n",
    "\n",
    "# 모델 평가 모드로 설정\n",
    "model.eval()\n",
    "model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 배치 단위 예측 함수\n",
    "def batch_predict(texts, batch_size=32):\n",
    "    predictions = []\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    for i in tqdm(range(0, len(texts), batch_size)):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        \n",
    "        # 토큰화 및 텐서 변환\n",
    "        inputs = tokenizer(\n",
    "            batch_texts.tolist(),\n",
    "            truncation=True,\n",
    "            padding=True,\n",
    "            max_length=128,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            batch_predictions = outputs.logits.argmax(dim=1).cpu().numpy()\n",
    "            predictions.extend(batch_predictions)\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# 배치 단위로 예측 수행\n",
    "new_data['target'] = batch_predict(new_data['text'])\n",
    "\n",
    "# 결과 저장\n",
    "new_data[['ID', 'text', 'target']].to_csv('/data/ephemeral/data/new_labeled_dataset_kobert_2.csv', index=False)\n",
    "\n",
    "print(\"Inference completed and results saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: monologg/koelectra-base-v3-discriminator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: klue/bert-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: beomi/kcbert-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference completed and results saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^가-힣a-zA-Z0-9\\s]', '', text)  \n",
    "    text = re.sub(r'\\s+', ' ', text).strip()         \n",
    "    return text\n",
    "\n",
    "\n",
    "new_data = pd.read_csv('/data/ephemeral/data/normal_texts_ID.csv')\n",
    "\n",
    "\n",
    "new_data['text'] = new_data['text'].apply(clean_text)\n",
    "\n",
    "\n",
    "model_names = [\n",
    "    'monologg/koelectra-base-v3-discriminator',\n",
    "    'klue/bert-base',\n",
    "    'beomi/kcbert-base',\n",
    "    # 'klue/roberta-large'\n",
    "]\n",
    "\n",
    "model_dir = './results'\n",
    "\n",
    "\n",
    "ensemble_logits = []\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "for model_name in model_names:\n",
    "    print(f\"Loading model: {model_name}\")\n",
    "    \n",
    "    # 모델과 전용 토크나이저 로드\n",
    "    if model_name in \"koelectra\":\n",
    "            tokenizer = ElectraTokenizer.from_pretrained(model_name)\n",
    "            model_path = f\"{model_dir}/{model_name.split('/')[-1]}\"\n",
    "            model = ElectraForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "    else:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model_path = f\"{model_dir}/{model_name.split('/')[-1]}\"\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "\n",
    "    inputs = tokenizer(\n",
    "        list(new_data['text']),\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits  \n",
    "        \n",
    "\n",
    "    logits = logits.cpu().numpy()\n",
    "    \n",
    "\n",
    "    ensemble_logits.append(logits)\n",
    "\n",
    "\n",
    "final_logits = np.mean(ensemble_logits, axis=0)\n",
    "\n",
    "\n",
    "probs = np.exp(final_logits) / np.exp(final_logits).sum(axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "final_predictions = final_logits.argmax(axis=1)\n",
    "\n",
    "\n",
    "new_data['target'] = final_predictions\n",
    "\n",
    "\n",
    "new_data[['ID', 'text', 'target']].to_csv('/data/ephemeral/data/new_labeled_dataset_ens.csv', index=False)\n",
    "\n",
    "print(\"Inference completed and results saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: monologg/koelectra-base-v3-discriminator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: klue/bert-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at klue/bert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: beomi/kcbert-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at beomi/kcbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference completed and results saved.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^가-힣a-zA-Z0-9\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "new_data = pd.read_csv('/data/ephemeral/data/normal_texts_ID.csv')\n",
    "new_data['text'] = new_data['text'].apply(clean_text)\n",
    "\n",
    "model_names = [\n",
    "    'monologg/koelectra-base-v3-discriminator',\n",
    "    'klue/bert-base',\n",
    "    'beomi/kcbert-base',\n",
    "    # 'klue/roberta-large'\n",
    "]\n",
    "\n",
    "# 각 모델의 가중치를 성능 점수에 따라 설정\n",
    "model_weights = [0.4, 0.4, 0.2]  # 성능에 따라 설정한 가중치 예시\n",
    "model_dir = './results'\n",
    "ensemble_logits = []\n",
    "\n",
    "for model_name, weight in zip(model_names, model_weights):\n",
    "    print(f\"Loading model: {model_name}\")\n",
    "    if model_name == 'monologg/koelectra-base-v3-discriminator':\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "    else:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        list(new_data['text']),\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "    logits = logits.cpu().numpy()\n",
    "    weighted_logits = logits * weight  # 가중치를 적용한 로짓\n",
    "    ensemble_logits.append(weighted_logits)\n",
    "\n",
    "# 가중 평균으로 최종 로짓 계산\n",
    "final_logits = np.sum(ensemble_logits, axis=0)\n",
    "probs = np.exp(final_logits) / np.exp(final_logits).sum(axis=1, keepdims=True)\n",
    "final_predictions = final_logits.argmax(axis=1)\n",
    "\n",
    "# 결과 저장\n",
    "new_data['target'] = final_predictions\n",
    "new_data[['ID', 'text', 'target']].to_csv('/data/ephemeral/data/new_labeled_dataset_ens.csv', index=False)\n",
    "\n",
    "print(\"Inference completed and results saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 데이터셋 로드\n",
    "data = pd.read_csv('/data/ephemeral/jung/merged_train_2_cleanlab.csv')\n",
    "\n",
    "# target 클래스 분포 확인\n",
    "target_counts = data['target'].value_counts()\n",
    "\n",
    "# 클래스 분포 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=target_counts.index, y=target_counts.values)\n",
    "plt.title(\"Target Class Distribution\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 두 개의 CSV 파일 불러오기\n",
    "df1 = pd.read_csv('/data/ephemeral/data/train_aug_test_cleaned.csv')\n",
    "df2 = pd.read_csv('/data/ephemeral/data/new_labeled_dataset_kobert.csv')\n",
    "\n",
    "# 두 데이터프레임을 위아래로 합치기\n",
    "merged_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# 결과를 새로운 CSV 파일로 저장\n",
    "merged_df.to_csv('merged_train_kobert.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 한번 모델로 정제 및 리라벨링 된 데이터에 대하여 LLM 으로 Zeroshot Sequentail Prompting 적용하여 라벨링 재시도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce2ff25cb04b45e38b21bf20952fba8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:   0%|          | 0/259 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   0%|          | 1/259 [00:49<3:32:47, 49.49s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   1%|          | 2/259 [01:39<3:33:10, 49.77s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   1%|          | 3/259 [02:29<3:32:49, 49.88s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   2%|▏         | 4/259 [03:19<3:31:57, 49.87s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   2%|▏         | 5/259 [04:09<3:31:17, 49.91s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   2%|▏         | 6/259 [04:59<3:30:20, 49.88s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   3%|▎         | 7/259 [05:49<3:29:54, 49.98s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   3%|▎         | 8/259 [06:39<3:29:03, 49.98s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   3%|▎         | 9/259 [07:29<3:28:08, 49.95s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   4%|▍         | 10/259 [08:19<3:27:11, 49.93s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   4%|▍         | 11/259 [09:08<3:26:00, 49.84s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   5%|▍         | 12/259 [09:58<3:24:49, 49.76s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   5%|▌         | 13/259 [10:47<3:23:52, 49.73s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   5%|▌         | 14/259 [11:37<3:23:11, 49.76s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   6%|▌         | 15/259 [12:27<3:22:00, 49.67s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   6%|▌         | 16/259 [13:16<3:21:15, 49.69s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   7%|▋         | 17/259 [14:07<3:20:57, 49.83s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   7%|▋         | 18/259 [14:59<3:23:26, 50.65s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   7%|▋         | 19/259 [16:03<3:38:07, 54.53s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   8%|▊         | 20/259 [17:06<3:47:43, 57.17s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   8%|▊         | 21/259 [18:05<3:48:38, 57.64s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   8%|▊         | 22/259 [18:55<3:38:44, 55.38s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Processing Batches:   9%|▉         | 23/259 [19:45<3:31:43, 53.83s/it]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 소형 Llama 모델 및 토크나이저 로드\n",
    "model_name = \"Bllossom/llama-3.2-Korean-Bllossom-3B\"  \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# 패딩 토큰 설정 (eos_token을 pad_token으로 사용)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# GPU 사용 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 데이터 로드\n",
    "file_path = '/data/ephemeral/jung/merged_train_2.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# 배치 크기 설정\n",
    "batch_size = 16\n",
    "\n",
    "# Llama 모델을 사용한 라벨 예측 함수 (배치 처리)\n",
    "def predict_labels_with_llama(texts):\n",
    "    # Step 1: 노이즈 필터링\n",
    "    filtered_texts = []\n",
    "    for text in texts:\n",
    "        filter_prompt = f\"다음 텍스트에서 핵심 정보만 남기고 불필요한 정보를 제거하세요.\\n\\n텍스트: \\\"{text}\\\"\\n정제된 텍스트:\"\n",
    "        inputs = tokenizer(filter_prompt, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "        outputs = model.generate(inputs.input_ids, attention_mask=inputs.attention_mask, max_new_tokens=50)  # attention_mask 추가\n",
    "        filtered_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        filtered_text = [t.split(\"정제된 텍스트:\")[-1].strip() for t in filtered_text]\n",
    "        filtered_texts.extend(filtered_text)\n",
    "\n",
    "    # Step 2: 범주 식별\n",
    "    categories = []\n",
    "    for filtered_text in filtered_texts:\n",
    "        category_prompt = f\"한국어 텍스트를 바탕으로, 이 텍스트가 0부터 6까지의 숫자 라벨 중 어느 범주에 속하는지 판단하세요.\\n\\n정제된 텍스트: \\\"{filtered_text}\\\"\\n범주:\"\n",
    "        inputs = tokenizer(category_prompt, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "        outputs = model.generate(inputs.input_ids, attention_mask=inputs.attention_mask, max_new_tokens=20)  # attention_mask 추가\n",
    "        category = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        category = [c.split(\"범주:\")[-1].strip() for c in category]\n",
    "        categories.extend(category)\n",
    "\n",
    "    # Step 3: 최종 라벨 할당\n",
    "    final_labels = []\n",
    "    for filtered_text, category in zip(filtered_texts, categories):\n",
    "        final_prompt = f\"이 텍스트는 한국어 데이터셋의 라벨 분포에 따라 0, 1, 2, 3, 4, 5, 6 중 하나의 숫자 라벨을 할당받아야 합니다. 최종 라벨을 할당하세요.\\n\\n정제된 텍스트: \\\"{filtered_text}\\\"\\n범주: {category}\\n라벨:\"\n",
    "        inputs = tokenizer(final_prompt, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "        outputs = model.generate(inputs.input_ids, attention_mask=inputs.attention_mask, max_new_tokens=20)  # attention_mask 추가\n",
    "        final_label = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        final_label = [f.split(\"라벨:\")[-1].strip() for f in final_label]\n",
    "\n",
    "        # 숫자 라벨로 변환\n",
    "        final_labels.extend([int(label) if label.isdigit() else None for label in final_label])\n",
    "\n",
    "    return final_labels\n",
    "\n",
    "# tqdm을 사용하여 각 배치에 대해 라벨 예측\n",
    "predicted_labels = []\n",
    "for i in tqdm(range(0, len(data), batch_size), desc=\"Processing Batches\"):\n",
    "    batch_texts = data['text'][i:i+batch_size].tolist()\n",
    "    predicted_labels.extend(predict_labels_with_llama(batch_texts))\n",
    "\n",
    "# 예측된 라벨을 데이터프레임에 추가\n",
    "data['predicted_target'] = predicted_labels\n",
    "\n",
    "# 라벨이 바뀐 개수 확인\n",
    "changed_labels_count = (data['target'] != data['predicted_target']).sum()\n",
    "print(f\"변경된 라벨 개수: {changed_labels_count}\")\n",
    "\n",
    "# 새 라벨로 업데이트한 후 CSV 파일로 저장\n",
    "output_file_path = '/data/ephemeral/jung/merged_train_2_llama_cleaned.csv'\n",
    "data.to_csv(output_file_path, index=False)\n",
    "print(f\"Llama를 통한 라벨링 개선된 데이터가 '{output_file_path}'에 저장되었습니다.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
